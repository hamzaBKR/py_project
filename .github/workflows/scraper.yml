name: Web Scraper CI

on:
  workflow_dispatch:  # Manual trigger only

jobs:
  # Job 1: Build container FIRST (this must run before scrape-with-container)
  build-container:
    name: Build Docker Image
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Log in to GitHub Container Registry
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}
      
      # Convert repository owner to lowercase for Docker compatibility
      - name: Set lowercase image name
        id: image_name
        run: |
          echo "image=ghcr.io/$(echo ${{ github.repository_owner }} | tr '[:upper:]' '[:lower:]')/scraper:latest" >> $GITHUB_OUTPUT
      
      - name: Build and push Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ steps.image_name.outputs.image }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # Job 2: Scrape with container (WAITS for build to complete)
  scrape-with-container:
    name: Scrape Data (Container)
    runs-on: ubuntu-latest
    needs: [build-container]  # ⭐ CRITICAL: Wait for container to be built first!
    
    container:
      image: ghcr.io/hamzabkr/scraper:latest  # ⭐ Lowercase username (Docker requirement)
      
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Run scraper
        run: python scraper.py
      
      - name: Upload results
        uses: actions/upload-artifact@v4
        with:
          name: scraping-results
          path: results.json
          retention-days: 30
      
      - name: Display results
        run: |
          echo "=== Scraping Results ==="
          cat results.json | python -m json.tool

  # Job 3: Scrape WITHOUT container (for comparison - may fail)
  scrape-without-container:
    name: Scrape Data (No Container - May Fail)
    runs-on: ubuntu-latest
    continue-on-error: true  # Don't fail the workflow if this fails
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      
      - name: Install Chrome
        run: |
          wget -q -O - https://dl-ssl.google.com/linux/linux_signing_key.pub | sudo apt-key add -
          sudo sh -c 'echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google.list'
          sudo apt-get update
          sudo apt-get install -y google-chrome-stable
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Run scraper
        run: python scraper.py
        # This might fail due to ChromeDriver version mismatches!
      
      - name: Upload results
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: scraping-results-no-container
          path: results.json

  # Job 4: Compare results and generate report
  compare-results:
    name: Compare Approaches
    runs-on: ubuntu-latest
    needs: [scrape-with-container, scrape-without-container]
    if: always()
    
    steps:
      - name: Download container results
        uses: actions/download-artifact@v4
        with:
          name: scraping-results
          path: ./container-results
        continue-on-error: true
      
      - name: Download no-container results
        uses: actions/download-artifact@v4
        with:
          name: scraping-results-no-container
          path: ./no-container-results
        continue-on-error: true
      
      - name: Generate comparison report
        run: |
          echo "# Scraping Results Comparison" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "./container-results/results.json" ]; then
            echo "✅ **Container approach**: SUCCESS" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`json" >> $GITHUB_STEP_SUMMARY
            cat ./container-results/results.json >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **Container approach**: FAILED" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f "./no-container-results/results.json" ]; then
            echo "✅ **No-container approach**: SUCCESS" >> $GITHUB_STEP_SUMMARY
          else
            echo "❌ **No-container approach**: FAILED (likely ChromeDriver mismatch)" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## Why Use Containers?" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Guaranteed Chrome/ChromeDriver compatibility" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Reproducible environment across all runs" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Same image used locally and in CI" >> $GITHUB_STEP_SUMMARY
          echo "- ✅ Faster execution (dependencies pre-installed)" >> $GITHUB_STEP_SUMMARY